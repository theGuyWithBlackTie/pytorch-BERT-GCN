{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x._values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nonzero_elems = 5\n",
    "noise_shape = [num_nonzero_elems]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = 0.7\n",
    "random_tensor = keep_prob\n",
    "temp = tf.random.uniform(noise_shape)\n",
    "print(temp)\n",
    "random_tensor += temp\n",
    "print(random_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFile = pd.read_csv('../data/full_context_PeerRead.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right_citated_text</th>\n",
       "      <th>left_citated_text</th>\n",
       "      <th>source_abstract</th>\n",
       "      <th>source_author</th>\n",
       "      <th>source_id</th>\n",
       "      <th>source_title</th>\n",
       "      <th>source_venue</th>\n",
       "      <th>source_year</th>\n",
       "      <th>target_id</th>\n",
       "      <th>target_author</th>\n",
       "      <th>target_abstract</th>\n",
       "      <th>target_year</th>\n",
       "      <th>target_title</th>\n",
       "      <th>target_venue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>andsyntactic parsing .Because RNNs make very f...</td>\n",
       "      <td>We conducted additional experiments on artific...</td>\n",
       "      <td>Deep Neural Networks (DNNs) are powerful model...</td>\n",
       "      <td>ilya sutskever;oriol vinyals;quoc v le</td>\n",
       "      <td>1409.3215v1</td>\n",
       "      <td>Sequence to Sequence Learning with Neural Netw...</td>\n",
       "      <td>NIPS</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1606.03622v1</td>\n",
       "      <td>robin jia;percy liang</td>\n",
       "      <td>Modeling crisp logical regularities is crucial...</td>\n",
       "      <td>2016</td>\n",
       "      <td>Data Recombination for Neural Semantic Parsing</td>\n",
       "      <td>ACL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.Because RNNs make very few domain-specific as...</td>\n",
       "      <td>We conducted additional experiments on artific...</td>\n",
       "      <td>Syntactic parsing is a fundamental problem in ...</td>\n",
       "      <td>oriol vinyals;lukasz kaiser;terry koo;slav pet...</td>\n",
       "      <td>1412.7449v1</td>\n",
       "      <td>Grammar as a Foreign Language</td>\n",
       "      <td>NIPS</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1606.03622v1</td>\n",
       "      <td>robin jia;percy liang</td>\n",
       "      <td>Modeling crisp logical regularities is crucial...</td>\n",
       "      <td>2016</td>\n",
       "      <td>Data Recombination for Neural Semantic Parsing</td>\n",
       "      <td>ACL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>; in a Pointer Network,the only way to generat...</td>\n",
       "      <td>Reproducibility. All code, data, and experimen...</td>\n",
       "      <td>We introduce a new neural architecture to lear...</td>\n",
       "      <td>oriol vinyals;meire fortunato;navdeep jaitly</td>\n",
       "      <td>1506.03134v1</td>\n",
       "      <td>Pointer Networks</td>\n",
       "      <td>NIPS</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1606.03622v1</td>\n",
       "      <td>robin jia;percy liang</td>\n",
       "      <td>Modeling crisp logical regularities is crucial...</td>\n",
       "      <td>2016</td>\n",
       "      <td>Data Recombination for Neural Semantic Parsing</td>\n",
       "      <td>ACL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>. Recently, nsur .  have shown superior perfor...</td>\n",
       "      <td>st like CWS and POS tagging, automatic prosody...</td>\n",
       "      <td>The recently introduced continuous Skip-gram m...</td>\n",
       "      <td>tomas mikolov;ilya sutskever;kai chen 0010;gre...</td>\n",
       "      <td>1310.4546v1</td>\n",
       "      <td>Distributed Representations of Words and Phras...</td>\n",
       "      <td>NIPS</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1511.00360v1</td>\n",
       "      <td>chuang ding;lei xie;jie yan;weini zhang;yang liu</td>\n",
       "      <td>Prosody affects the naturalness and intelligib...</td>\n",
       "      <td>2015</td>\n",
       "      <td>Automatic Prosody Prediction for Chinese Speec...</td>\n",
       "      <td>arxiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model trained on the Google News dataset3.In a...</td>\n",
       "      <td>We begin by considering a document as the set ...</td>\n",
       "      <td>The recently introduced continuous Skip-gram m...</td>\n",
       "      <td>tomas mikolov;ilya sutskever;kai chen 0010;gre...</td>\n",
       "      <td>1310.4546v1</td>\n",
       "      <td>Distributed Representations of Words and Phras...</td>\n",
       "      <td>NIPS</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1705.10900v1</td>\n",
       "      <td>paul michel;abhilasha ravichander;shruti rijhwani</td>\n",
       "      <td>We investigate the pertinence of methods from ...</td>\n",
       "      <td>2017</td>\n",
       "      <td>Does the Geometry of Word Embeddings Help Docu...</td>\n",
       "      <td>arxiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>to create a sentence embedding. Second, from e...</td>\n",
       "      <td>For each word in the sentence we calculate var...</td>\n",
       "      <td>In this paper we compare different types of re...</td>\n",
       "      <td>junyoung chung;caglar gulcehre;kyunghyun cho;y...</td>\n",
       "      <td>1412.3555v1</td>\n",
       "      <td>Empirical Evaluation of Gated Recurrent Neural...</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1708.05582v1</td>\n",
       "      <td>sushant hiray;venkatesh duppada</td>\n",
       "      <td>This paper presents models for detecting agree...</td>\n",
       "      <td>2017</td>\n",
       "      <td>Agree to Disagree: Improving Disagreement Dete...</td>\n",
       "      <td>arxiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>for accelerating training. The network is opti...</td>\n",
       "      <td>For each Q-R pair we extract two sets of featu...</td>\n",
       "      <td>Training Deep Neural Networks is complicated b...</td>\n",
       "      <td>sergey ioffe;christian szegedy</td>\n",
       "      <td>1502.03167v1</td>\n",
       "      <td>Batch Normalization: Accelerating Deep Network...</td>\n",
       "      <td>ICML</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1708.05582v1</td>\n",
       "      <td>sushant hiray;venkatesh duppada</td>\n",
       "      <td>This paper presents models for detecting agree...</td>\n",
       "      <td>2017</td>\n",
       "      <td>Agree to Disagree: Improving Disagreement Dete...</td>\n",
       "      <td>arxiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>optimizer with learning rate of 0.001. We have...</td>\n",
       "      <td>For each Q-R pair we extract two sets of featu...</td>\n",
       "      <td>We introduce Adam, an algorithm for first-orde...</td>\n",
       "      <td>diederik p kingma;jimmy ba</td>\n",
       "      <td>1412.6980v1</td>\n",
       "      <td>Adam: A Method for Stochastic Optimization</td>\n",
       "      <td>iclr</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1708.05582v1</td>\n",
       "      <td>sushant hiray;venkatesh duppada</td>\n",
       "      <td>This paper presents models for detecting agree...</td>\n",
       "      <td>2017</td>\n",
       "      <td>Agree to Disagree: Improving Disagreement Dete...</td>\n",
       "      <td>arxiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>, and convolutional neural networks  have show...</td>\n",
       "      <td>Modeling textual or visual information with ve...</td>\n",
       "      <td>Deep Neural Networks (DNNs) are powerful model...</td>\n",
       "      <td>ilya sutskever;oriol vinyals;quoc v le</td>\n",
       "      <td>1409.3215v1</td>\n",
       "      <td>Sequence to Sequence Learning with Neural Netw...</td>\n",
       "      <td>NIPS</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1606.01847v1</td>\n",
       "      <td>akira fukui;dong huk park;daylen yang;anna roh...</td>\n",
       "      <td>Modeling textual or visual information with ve...</td>\n",
       "      <td>2016</td>\n",
       "      <td>Multimodal Compact Bilinear Pooling for Visual...</td>\n",
       "      <td>EMNLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>use concatenation and fully connected layers t...</td>\n",
       "      <td>In this paper, we propose to rely on ltimodal ...</td>\n",
       "      <td>We describe a very simple bag-of-words baselin...</td>\n",
       "      <td>bolei zhou;yuandong tian;sainbayar sukhbaatar;...</td>\n",
       "      <td>1512.02167v1</td>\n",
       "      <td>Simple Baseline for Visual Question Answering</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1606.01847v1</td>\n",
       "      <td>akira fukui;dong huk park;daylen yang;anna roh...</td>\n",
       "      <td>Modeling textual or visual information with ve...</td>\n",
       "      <td>2016</td>\n",
       "      <td>Multimodal Compact Bilinear Pooling for Visual...</td>\n",
       "      <td>EMNLP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   right_citated_text  \\\n",
       "0   andsyntactic parsing .Because RNNs make very f...   \n",
       "1   .Because RNNs make very few domain-specific as...   \n",
       "2   ; in a Pointer Network,the only way to generat...   \n",
       "3   . Recently, nsur .  have shown superior perfor...   \n",
       "4   model trained on the Google News dataset3.In a...   \n",
       "..                                                ...   \n",
       "95  to create a sentence embedding. Second, from e...   \n",
       "96  for accelerating training. The network is opti...   \n",
       "97  optimizer with learning rate of 0.001. We have...   \n",
       "98  , and convolutional neural networks  have show...   \n",
       "99  use concatenation and fully connected layers t...   \n",
       "\n",
       "                                    left_citated_text  \\\n",
       "0   We conducted additional experiments on artific...   \n",
       "1   We conducted additional experiments on artific...   \n",
       "2   Reproducibility. All code, data, and experimen...   \n",
       "3   st like CWS and POS tagging, automatic prosody...   \n",
       "4   We begin by considering a document as the set ...   \n",
       "..                                                ...   \n",
       "95  For each word in the sentence we calculate var...   \n",
       "96  For each Q-R pair we extract two sets of featu...   \n",
       "97  For each Q-R pair we extract two sets of featu...   \n",
       "98  Modeling textual or visual information with ve...   \n",
       "99  In this paper, we propose to rely on ltimodal ...   \n",
       "\n",
       "                                      source_abstract  \\\n",
       "0   Deep Neural Networks (DNNs) are powerful model...   \n",
       "1   Syntactic parsing is a fundamental problem in ...   \n",
       "2   We introduce a new neural architecture to lear...   \n",
       "3   The recently introduced continuous Skip-gram m...   \n",
       "4   The recently introduced continuous Skip-gram m...   \n",
       "..                                                ...   \n",
       "95  In this paper we compare different types of re...   \n",
       "96  Training Deep Neural Networks is complicated b...   \n",
       "97  We introduce Adam, an algorithm for first-orde...   \n",
       "98  Deep Neural Networks (DNNs) are powerful model...   \n",
       "99  We describe a very simple bag-of-words baselin...   \n",
       "\n",
       "                                        source_author     source_id  \\\n",
       "0              ilya sutskever;oriol vinyals;quoc v le   1409.3215v1   \n",
       "1   oriol vinyals;lukasz kaiser;terry koo;slav pet...   1412.7449v1   \n",
       "2        oriol vinyals;meire fortunato;navdeep jaitly  1506.03134v1   \n",
       "3   tomas mikolov;ilya sutskever;kai chen 0010;gre...   1310.4546v1   \n",
       "4   tomas mikolov;ilya sutskever;kai chen 0010;gre...   1310.4546v1   \n",
       "..                                                ...           ...   \n",
       "95  junyoung chung;caglar gulcehre;kyunghyun cho;y...   1412.3555v1   \n",
       "96                     sergey ioffe;christian szegedy  1502.03167v1   \n",
       "97                         diederik p kingma;jimmy ba   1412.6980v1   \n",
       "98             ilya sutskever;oriol vinyals;quoc v le   1409.3215v1   \n",
       "99  bolei zhou;yuandong tian;sainbayar sukhbaatar;...  1512.02167v1   \n",
       "\n",
       "                                         source_title source_venue  \\\n",
       "0   Sequence to Sequence Learning with Neural Netw...         NIPS   \n",
       "1                       Grammar as a Foreign Language         NIPS   \n",
       "2                                    Pointer Networks         NIPS   \n",
       "3   Distributed Representations of Words and Phras...         NIPS   \n",
       "4   Distributed Representations of Words and Phras...         NIPS   \n",
       "..                                                ...          ...   \n",
       "95  Empirical Evaluation of Gated Recurrent Neural...        arxiv   \n",
       "96  Batch Normalization: Accelerating Deep Network...         ICML   \n",
       "97         Adam: A Method for Stochastic Optimization         iclr   \n",
       "98  Sequence to Sequence Learning with Neural Netw...         NIPS   \n",
       "99      Simple Baseline for Visual Question Answering        arxiv   \n",
       "\n",
       "    source_year     target_id  \\\n",
       "0        2014.0  1606.03622v1   \n",
       "1        2014.0  1606.03622v1   \n",
       "2        2015.0  1606.03622v1   \n",
       "3        2013.0  1511.00360v1   \n",
       "4        2013.0  1705.10900v1   \n",
       "..          ...           ...   \n",
       "95       2014.0  1708.05582v1   \n",
       "96       2015.0  1708.05582v1   \n",
       "97       2014.0  1708.05582v1   \n",
       "98       2014.0  1606.01847v1   \n",
       "99       2015.0  1606.01847v1   \n",
       "\n",
       "                                        target_author  \\\n",
       "0                               robin jia;percy liang   \n",
       "1                               robin jia;percy liang   \n",
       "2                               robin jia;percy liang   \n",
       "3    chuang ding;lei xie;jie yan;weini zhang;yang liu   \n",
       "4   paul michel;abhilasha ravichander;shruti rijhwani   \n",
       "..                                                ...   \n",
       "95                    sushant hiray;venkatesh duppada   \n",
       "96                    sushant hiray;venkatesh duppada   \n",
       "97                    sushant hiray;venkatesh duppada   \n",
       "98  akira fukui;dong huk park;daylen yang;anna roh...   \n",
       "99  akira fukui;dong huk park;daylen yang;anna roh...   \n",
       "\n",
       "                                      target_abstract  target_year  \\\n",
       "0   Modeling crisp logical regularities is crucial...         2016   \n",
       "1   Modeling crisp logical regularities is crucial...         2016   \n",
       "2   Modeling crisp logical regularities is crucial...         2016   \n",
       "3   Prosody affects the naturalness and intelligib...         2015   \n",
       "4   We investigate the pertinence of methods from ...         2017   \n",
       "..                                                ...          ...   \n",
       "95  This paper presents models for detecting agree...         2017   \n",
       "96  This paper presents models for detecting agree...         2017   \n",
       "97  This paper presents models for detecting agree...         2017   \n",
       "98  Modeling textual or visual information with ve...         2016   \n",
       "99  Modeling textual or visual information with ve...         2016   \n",
       "\n",
       "                                         target_title target_venue  \n",
       "0      Data Recombination for Neural Semantic Parsing          ACL  \n",
       "1      Data Recombination for Neural Semantic Parsing          ACL  \n",
       "2      Data Recombination for Neural Semantic Parsing          ACL  \n",
       "3   Automatic Prosody Prediction for Chinese Speec...        arxiv  \n",
       "4   Does the Geometry of Word Embeddings Help Docu...        arxiv  \n",
       "..                                                ...          ...  \n",
       "95  Agree to Disagree: Improving Disagreement Dete...        arxiv  \n",
       "96  Agree to Disagree: Improving Disagreement Dete...        arxiv  \n",
       "97  Agree to Disagree: Improving Disagreement Dete...        arxiv  \n",
       "98  Multimodal Compact Bilinear Pooling for Visual...        EMNLP  \n",
       "99  Multimodal Compact Bilinear Pooling for Visual...        EMNLP  \n",
       "\n",
       "[100 rows x 14 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFile.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['left_citated_text', 'right_citated_text', 'target_id', 'source_id', 'target_year','target_author']\n",
    "frequency = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataFile[column]\n",
    "source_cut_data = df[['target_id', 'source_id']].drop_duplicates(subset=['target_id', 'source_id'])\n",
    "source_cut = source_cut_data.source_id.value_counts()[(source_cut_data.source_id.value_counts() >= frequency)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_id = np.sort(source_cut.keys())\n",
    "source_id\n",
    "df = df.loc[df['source_id'].isin(source_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['#1 String'] = df['left_citated_text'].str[-128:]\n",
    "df['#2 String'] = df['right_citated_text'].str[:128]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_citated_text  = df['#1 String'].values.tolist()\n",
    "right_citated_text = df['#2 String'].values.tolist()\n",
    "total_citated_text = list(set(left_citated_text + right_citated_text))\n",
    "citated_voca = {}\n",
    "left_citated_id = []\n",
    "right_citated_id = []\n",
    "for i, v in enumerate(total_citated_text):\n",
    "    citated_voca[v] = i\n",
    "citated_voca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l, r in zip(df['#1 String'], df['#2 String']):\n",
    "        left_citated_id.append(citated_voca[l])\n",
    "        right_citated_id.append(citated_voca[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['#1 ID'] = left_citated_id\n",
    "df['#2 ID'] = right_citated_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2017\n",
    "train_idx = df['target_year'][df['target_year'] < year].index\n",
    "test_idx = df['target_year'][df['target_year'] >= year].index\n",
    "train_df = df.loc[train_idx]\n",
    "test_df = df.loc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_column = ['Quality', '#1 ID', '#2 ID', '#1 String', '#2 String', 'target_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit_transform(df['source_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg_label': 0, 'pos_label': 1, 'sparse_output': False}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_argmax(df, lb):\n",
    "\n",
    "    y = df['source_id'].values\n",
    "    y = lb.transform(y)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    df['Quality'] = y\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1 = convert_argmax(train_df, lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1 = convert_argmax(test_df, lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_df1[bert_column], test_df1[bert_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df['#1 ID'] == 14050]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_label_info = []\n",
    "for i in temp_df.groupby(['#1 ID', '#2 ID']):\n",
    "    instance_label = {}\n",
    "    instance_label['Quality'] = i[1]['Quality'].values\n",
    "    instance_label['index'] = i[1]['Quality'].index.values\n",
    "    multi_label_info.append(instance_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,len(multi_label_info)):\n",
    "    if multi_label_info[i]['index'].any() == 0:\n",
    "        print(multi_label_info[i])\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_label_info[0]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: HI \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import transformers\n",
    "import torch\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2017, 2024, 2478, 28315, 2544, 1012, 102, 2074, 2066, 1037, 3427, 8962, 2196, 26077, 2015, 1010, 1037, 3427, 2005, 7077, 2196, 4515, 1012, 2043, 7149, 2007, 2312, 2951, 13462, 2015, 1010, 2130, 1996, 21304, 3136, 2064, 2202, 2847, 1012, 5082, 6963, 2064, 2393, 2191, 2951, 6364, 5841, 2625, 1997, 1037, 14978, 2138, 1024, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode_plus(\"You are using pip version.\",\"Just like a watched pot never boils, a watched for loop never ends. When dealing with large datasets, even the simplest operations can take hours. Progress bars can help make data processing jobs less of a headache because:\",  add_special_tokens = True, max_length = 100, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2017, 2024, 2478, 12567, 28315, 2544, 1012, 2074, 2066, 1037, 3427, 8962, 2196, 26077, 2015, 1010, 1037, 3427, 2005, 7077, 2196, 4515, 1012, 2043, 7149, 2007, 2312, 2951, 13462, 2015, 1010, 2130, 1996, 21304, 3136, 2064, 2202, 2847, 1012, 5082, 6963, 2064, 2393, 2191, 2951, 6364, 5841, 2625, 1997, 1037, 14978, 2138, 1024], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode_plus(\"You are using 117 pip version. Just like a watched pot never boils, a watched for loop never ends. When dealing with large datasets, even the simplest operations can take hours. Progress bars can help make data processing jobs less of a headache because:\", None, add_special_tokens = False, max_length = 100, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[CLS]', 101)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.cls_token, tokenizer.cls_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using pip version.Just like a watched pot never boils\n"
     ]
    }
   ],
   "source": [
    "context = \"You are using pip version.Just like a watched pot never boils\"\n",
    "print(\" \".join(context.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"andsyntactic parsing .Because RNNs make very few domain-specific assumptions,they have the potential to succeed at a wide variety of taskswith minimal feature engineering.wever, this flexibility also puts RNNs at a disadvantage compared tostandard semantic parsers, which can generalize naturallyby leveraging their built-in awareness of logical compositionality.In this paper, we introduce data recombination,a generic framework for declaratively injecting prior knowledgeinto a domain-general structured prediction model.In data recombination, prior knowledge about a taskis used to build a high-precision generative modelthat expands the empirical distributionby allowing fragments of different examples to be combined inparticular ways.mples from this generative model are then used to train a domain-general model.In the case of semantic parsing, we construct a generative modelby inducing a synchronous context-free grammar ,creating new examples such as those shown in Figure 1;our domain-general model is a sequence-to-sequence RNNwith a novel attention-based copying mechanism.Data recombination boosts the accuracyof our RNN model on three semantic parsing datasets. the o dataset, data recombinationimproves test accuracy by 4.3 percentage pointsover our baseline RNN, leading to newstate-of-the-art results for models that do not use aseed lexicon for predicates.ox: “what is the population of iowa ?”y: _answer  , _const    ATISx: “can you list all flights from chicago to milwaukee”y:  _lambda $0 e  _and  _flight $0  _from $0 chicago : _ci  _to $0 milwaukee : _ci   Overnightx: “when is the weekly standup”y:  call listValue  callgetProperty meeting.weekly_standup string start_time   We cast semantic parsing as a sequence-to-sequence task.The input utterance x is a sequence of words x1,...,xm∈Vin, the input vocabulary;similarly, the output logical form y isa sequence of tokens y1,...,yn∈Vout, the output vocabulary.A linear sequence of tokens might appear tolose the hierarchical structure of a logical form,but there is precedent for this choice:newcitevinyals2015grammarshowed that an RNN can reliably predict tree-structured outputsin a linear fashion.We evaluate our system on three existing semantic parsing datasets.Figure 2 shows sample input-output pairs from each of these datasets.oery o containsnatural language questions about US geographypaired with corresponding Prolog database queries.We use the standard split of 600 training examples and 280 test examplesintroduced by newcitezettlemoyer05ccg.We preprocess the logical forms to De Brujin index notationto standardize variable naming.ATIS ATIS containsnatural language queries for a flights databasepaired with corresponding database querieswritten in lambda calculus.We train on 4473 examples and evaluate on the 448test examples used bynewcitezettlemoyer07relaxed.Overnight Overnight containslogical forms paired with natural languageparaphrases across eight varied subdomains.newcitewang2015overnight constructed the datasetby generating all possible logicalforms up to some depth threshold,then getting multiple natural language paraphrasesfor each logical form from workers on Amazon Mechanical rk.We evaluate on the same train/test splits asnewcitewang2015overnight.In this paper, we only explore learning from logical forms.In the last few years, there has an emergence ofsemantic parsers learned from denotations.While our system cannot directly learn from denotations,it could be used to rerank candidate derivationsgenerated by one of these other systems.Our sequence-to-sequence RNN model is based on existingattention-based neural machine translation models,but also includes a novel attention-based copying mechanism.milar copying mechanisms have been exploredin parallel by newcitegu2016copying and newcitegulcehre2016pointing.Encoder. The encoder converts the input sequence x1,...,xminto a sequence of context-sensitive embeddingsb1,...,bm using a bidirectional RNN .First, a word embedding function φinmaps each word xi to a fixed-dimensional vector.These vectors are fed as input to two RNNs: a forward RNN and a backward RNN.The forward RNN starts with an initial hidden state hF0,and generates a sequence of hidden states hF1,...,hFm byrepeatedly applying the recurrenceThe recurrence takes the form of an LSTM .The backward RNN similarly generates hidden states hBm,...,hB1by processing the input sequence in reverse order.Finally, for each input position i, we definethe context-sensitive embeddingbi to be the concatenation of hFi and hDecoder. The decoder is an attention-based modelthat generates the output sequence y1,...,ynone token at a time. At each time step j,it writes yj based on thecurrent hidden state sj, then updates the hiddenstate to sj+1 based on sj and yj.Formally, the decoder is defined by the following equations:When not specified, i ranges over {1,...,m}and j ranges over {1,...,n}.Intuitively, the αji’s define a probabilitydistribution over the input words,describing what words in the input the decoder is focusing on at time j.They are computed from the unnormalizedattention scores eji.The matrices Ws, Wa, and U,as well as the embedding function φout, are parameters of the model.In the basic model of the previous section,the next output word yj is chosenvia a simple softmax over all words in the output vocabulary.wever, this model has difficulty generalizing to the long tail ofentity names commonly found in semantic parsing datasets.Conveniently, entity names in the input often corresponddirectly to tokens in the outpute.g., “iowa” becomes iowa in Figure 2.1To capture this intuition, we introducea new attention-based copying mechanism.At each time step j, the decodergenerates one of two types of actions.As before, it can write any word in the output vocabulary.In addition, it can copy any input word xi directly to the output,where the probability with which we copy xi is determined by theattention score on xi.Formally, we define a latent action ajthat is either Write for some w∈Voutor Copy for some i∈{1,...,m}.We then haveThe decoder chooses aj with a softmax over all these possible actions;yj is then a deterministic function of aj and x.ring training, we maximize the log-likelihood of y,marginalizing out a.Attention-based copying can be seen as acombination of a standard softmax output layer of an attention-based model and a Pointer Network ; in a Pointer Network,the only way to generate output is to copy a symbol from the input.Examples“what states border texas ?”,answerNV, stateV0, next_toV0, NV, constV0, stateidtexas“what is the highest mountain in ohio ?”,answerNV, highestV0, mountainV0, locV0, NV, constV0, stateidohioRules created by AbsEntitiesRoot →⟨ “what states border Id ?”,answerNV, stateV0, next_toV0, NV, constV0, stateidId ⟩Id →⟨ “texas”, texas ⟩Root →⟨ “what is the highest mountain in Id ?”,answerNV, highestV0, mountainV0, locV0, NV, constV0, stateidId ⟩Id →⟨“ohio”, ohio⟩Rules created by AbsWholePhrasesRoot →⟨ “what states border  ?”, answerNV, stateV0, next_toV0, NV,  ⟩ →⟨ “states border texas”, stateV0, next_toV0, NV, constV0, stateidtexas⟩Root →⟨ “what is the highest mountain in  ?”,answerNV, highestV0, mountainV0, locV0, NV,  ⟩Rules created by Concat-2Root →⟨textsct1 </s> textsct2,textsct1 </s> textsct2⟩t →⟨ “what states border texas ?”,answerNV, stateV0, next_toV0, NV, constV0, stateidtexas ⟩t →⟨ “what is the highest mountain in ohio ?”,answerNV, highestV0, mountainV0, locV0, NV, constV0, stateidohio⟩The main contribution of this paper is a novel data recombination frameworkthat injects important prior knowledge into our oblivious sequence-to-sequence RNN.In this framework, we induce a high-precisiongenerative model from the training data,then sample from it to generate new training examples.The process of inducing this generative modelcan leverage any available prior knowledge,which is transmitted through the generated examplesto the RNN model.A key advantage of our two-stage approach is that it allows us todeclare desired properties of the task which might be hard to capturein the model architecture.Our approach generalizes data augmentation,which is commonly employed to inject prior knowledge into a model.Data augmentation techniques focus on modelinginvariances—transformations liketranslating an image or adding noisethat alter the inputs x,but do not change the output y.These techniques have proven effective in areas likecomputer vision and speech recognition .In semantic parsing, however,we would like to capture more than just invariance properties.Consider an example with the utterance “what states border texas ?”.Given this example, it should be easy togeneralize to questions where “texas”is replaced by the name of any other state:simply replace the mention of Texas in the logical formwith the name of the new state.Underlying this phenomenon is a strong conditional independence principle:the meaning of the rest of the sentence is independent of thename of the state in question.Standard data augmentation is not sufficient to model such phenomena:instead of holding y fixed,we would like to apply simultaneous transformations to x and ysuch that the new x still maps to the new y.Data recombination addresses this need.In the general setting of data recombination,we start with a training set D of x,y pairs,which defines the empirical distribution ^px,y.We then fit a generative model ~px,y to ^pwhich generalizes beyond the support of ^p,for example by splicing together fragments of different examples.We refer to examples in the support of ~p as recombinant examples.Finally, to train our actual model pθy∣x,we maximize the expected value oflogpθy∣x, where x,y is drawn from ~p.For semantic parsing, we induce a synchronous context-free grammar to serve as the backbone of our generative model ~p.An SCFG consists of a set of production rulesX→⟨α,β⟩, where X is a category non-terminal,and α and β are sequences of terminal and non-terminal symbols.Any non-terminal symbols in α mustbe aligned to the same non-terminal symbol in β,and vice versa.Therefore, an SCFG defines a set of joint derivations ofaligned pairs of strings.In our case, we use an SCFG to represent joint derivationsof utterances x and logical forms y which for us is just a sequence of tokens.After we induce an SCFG G from D,the corresponding generative model ~px,yis the distribution over pairs x,ydefined by sampling from G,where we choose production rules to apply uniformly at random.It is instructive to compare our SCFG-based data recombination withWasp ,which uses an SCFG as the actual semantic parsing model.The grammar induced by Waspmust have good coverage in order to generalize to new inputsat test time.Wasp also requires the implementation of anefficient algorithm for computing the conditionalprobability py∣x.In contrast, our SCFG is only used to conveyprior knowledge about conditional independence structure,so it only needs to have high precision;our RNN model is responsible for boosting recallover the entire input space.We also only need to forward sample from the SCFG, which isconsiderably easier to implement than conditional inference.Below, we examine various strategies for inducinga grammar G from a dataset D.We first encode D as an initial grammarwith rules Root →⟨x,y⟩for each x,y∈D.Next, we will define each grammar induction strategyas a mapping from an input grammar Gin to a new grammar Gout.This formulation allows us to compose grammar induction strategiesSection 4.3.4.Our first grammar induction strategy, AbsEntities, simply abstracts entitieswith their types.We assume that each entity e e.g., texashas a corresponding type e.t e.g., state,which we infer based on the presence of certain predicates in the logical forme.g. stateid.For each grammar rule X→⟨α,β⟩ in Gin,where α contains a token e.g., “texas” thatstring matches an entity e.g., texas in β,we add two rules to Gout:i a rule where both occurrences are replaced with the type of the entitye.g., state,and ii a new rule that maps the type to the entity e.g.,textscId→⟨``{texas}'',texas⟩;we reserve the category name  for the next section.Thus, Gout generates recombinant examplesthat fuse most of one example with an entity found in a second example.A concrete example from the o domain is given inFigure 3.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFile[\"right_citated_text\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
